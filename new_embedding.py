# -*- coding: utf-8 -*-
"""new embedding

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/193AAZ03Ntqv8Ij6GLwTETaIKSLOXZv0T
"""

pip install transformers

import nltk
import re
import string
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')
st = nltk.PorterStemmer()
lm = nltk.WordNetLemmatizer()

stop_words = set(stopwords.words("kazakh"))

from transformers import BertTokenizer, TFBertModel
tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')
model = TFBertModel.from_pretrained("bert-base-multilingual-cased")
def rep(text):
    encoded_input = tokenizer(text, return_tensors='tf').input_ids
    output = model(encoded_input)
    return output

from sklearn.metrics.pairwise import cosine_similarity

with open('question.txt', 'r', encoding='utf-8') as file:
    a = file.read()

with open('answer.txt', 'r', encoding='utf-8') as file:
    b = file.read()

question = a.split("\n")
answer = b.split("\n")
print(len(question), len(answer))

import pandas as pd

df = pd.DataFrame({
    "Question": question,
    "Answer": answer
})
df

def tazartu(text):
    n_zhok = text.replace("\n", "")
    text_tazar = "".join([i for i in n_zhok if i not in string.punctuation])
    token = re.split("\W+", text)
    stop_w = [j.lower() for j in token if j not in stop_words]
    sting = [st.stem(w) for w in stop_w]
    lmize = " ".join([lm.lemmatize(k) for k in sting])
    return lmize

df["new_question"] = df["Question"].apply(lambda x: tazartu(x))
df

import tensorflow as tf
import numpy

df["sim"] = df["new_question"].apply(lambda x: tf.reduce_mean(rep(x).last_hidden_state, axis=1).numpy())

df

def ask_question(question):
    question = tazartu(question)
    query_vect = rep(question)
    e1 = tf.reduce_mean(query_vect.last_hidden_state, axis=1).numpy()
    df["max_s"] = df["sim"].apply(lambda x: cosine_similarity(e1, x)[0][0])
    max_s = df[df["max_s"]==df["max_s"].max()].iloc[0]["new_question"]
    ans = df[df["max_s"]==df["max_s"].max()].iloc[0]["Answer"]
    sims = df[df["max_s"]==df["max_s"].max()].iloc[0]["max_s"]

    print('Your question:', question)
    print('Closest question found:', max_s)
    print("Answer:", ans)
    print("Similarity:", sims)

ask_question("2015 жылы қай ұйымға мүше болды?")